<!doctype html>
<html lang="en">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css" integrity="sha384-gfdkjb5BdAXd+lj+gudLWI+BXq4IuLW5IT+brZEZsLFm++aCMlF1V92rMkPaX4PP" crossorigin="anonymous">

    <!-- Highlight.js-->
    <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.13.1/highlight.min.js"></script>
    <script>
        hljs.initHighlightingOnLoad();

    </script>

    <!-- Custom CSS-->
    <link rel="stylesheet" href="/css/style.css">
    <link rel="stylesheet" href="/css/monokai-sublime.css">

    <title>Image Inpainting</title>
    <script src="https://code.jquery.com/jquery-1.10.2.js"></script>
    
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-132190435-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'UA-132190435-1');
    </script>

</head>

<body>
    <div class="container">

        <!--Navigation Bar-->
        <div id="nav-placeholder"></div>
        <script>
            $(function() {
                $("#nav-placeholder").load("nav.html");
            });

        </script>

        <!--Content-->
        <div class="title">
            <a class="nav-link fab fa-lg fa-github icon-cog" href="https://github.com/joshilp/ImageInpainting"></a> 
            <p class="nospace">Applying Image Inpainting to Video Post Production</p>
        </div>
        
        
        
        

        <h5 class="heading-section">Contributors</h5>
        <hr>
        <ul>
            <li>Joshil Patel</li>
            <li><a href="https://disigns.wordpress.com">Di Wang</a></li>
            <li>Bryce Haley</li>
            <li>Kino Roy</li>
            <li>Hyukho Kwon</li>
        </ul>
        
        


        <h5 class="heading-section">Problem &amp; Objective</h5>
        <hr>

        <h6 class="heading">Problem Description</h6>
        <p>
            Individual shots in a movie require a great deal of visual effects (VFX) work before the final film is released on the big screen. One tedious and time consuming task involves artists removing or replacing objects in a scene, which is known in the industry as painting. The majority of shots in a film require paint work, resulting in a bottleneck in the VFX pipeline and therefore increasing the risk of late delivery.
        </p>

        <h6 class="heading">Painting Process</h6>
        <ul>
            <li>create a mask of the object </li>
            <li>stencil out the image using that mask</li>
            <li>paint in the hole using various VFX techniques</li>
        </ul>

        <h6 class="heading">Objective</h6>
        <p>
            To automate the painting process using machine learning, thus removing or reducing the bottleneck in the VFX pipeline.
        </p>
        
        
        
        <h5 class="heading-section">Approach</h5>
        <hr>
        
        <h6 class="heading">Convolutional Layer Input</h6>
        <p>
            Let ğ‘¾<sup>ğ‘‡</sup> be the weights for the convolution filter and ğ‘ be the corresponding bias. ğ‘¿ are the pixels values for the current convolution window and ğ‘´ is the corresponding binary mask.
        </p>
        
        <h6 class="heading">Mask Updating</h6>
        <p>
            The mask is updated after each partial convolution. If the convolution was able to condition its output on at least one valid input value, then remove the mask for that location.
        </p>
        
        <h6 class="heading">Loss Function</h6>

        <p class="math">
            ğ“›<sub>ğ‘¡ğ‘œğ‘¡ğ‘ğ‘™</sub> = ğ“›<sub>ğ‘£ğ‘ğ‘™ğ‘–ğ‘‘</sub> + 6<sub>ğ“›â„ğ‘œğ‘™ğ‘’</sub> + 0.05<sub>ğ“›ğ‘ğ‘’ğ‘Ÿğ‘ğ‘’ğ‘ğ‘¡ğ‘¢ğ‘ğ‘™</sub> + 120 ğ“›<sub>ğ‘ ğ‘¡ğ‘¦ğ‘™ğ‘’<sub>ğ‘œğ‘¢ğ‘¡</sub></sub> + ğ“›<sub>ğ‘ ğ‘¡ğ‘¦ğ‘™ğ‘’<sub>ğ‘ğ‘œğ‘šğ‘</sub></sub> + 0.1ğ“›<sub>ğ‘¡v</sub>
        </p>

        
        
        
        
        <h5 class="heading-section">U-Net Architecure</h5>
        <hr>
        
        <div>
            <img class="image-full" src="images/Image-Inpainting/unet.jpg">
        </div>
        
        
                
        <h5 class="heading-section">Maybe things make more sense in code...</h5>
        <hr>
        
        <pre>
        <code class="python">
            BATCH_SIZE = 4

            def plot_images(images, s=5):
                _, axes = plt.subplots(1, len(images), figsize=(s*len(images), s))
                if len(images) == 1:
                    axes = [axes]
                for img, ax in zip(images, axes):
                    ax.imshow(img)
                plt.show()

            weights = r'data\logs\157_weights_2018-12-03-14-14-46.h5'

            with tf.device('/cpu:0'):
                model = PConvUnet(weight_filepath='data/logs/')
                model.load(weights, train_bn=False)

            num = ['00','01','02','03','04','05','06','07']

            for i in num:

                footage_number = i

                footage = 'data/footage/' + footage_number +'/footage/*.png'
                masks = 'data/footage/' + footage_number +'/mask/*.png'
                prediction = 'data/footage/' + footage_number + '/prediction'

                img_lst = []
                mask_lst = []

                for filename in glob.glob(footage):
                    im = Image.open(filename)
                    img_lst.append(im)

                for filename in glob.glob(masks):
                    mask_lst.append(filename)

                _, footage_axes = plt.subplots((int)(len(img_lst)/3)+1, 3, figsize=(15, 15))

                imgs, msks = [], []
                for im, mk, ax in zip(img_lst, mask_lst, footage_axes.flatten()):
                    im = np.array(im) / 255
                    mask = get_mask(mk)
                    im[mask==0] = 1
                    imgs.append(im)
                    msks.append(mask)

                fig, pred_axes = plt.subplots((int)(len(img_lst)/3)+1, 3, figsize=(15, 15))

                counter = 0

                for im, mk, ax in zip(imgs, msks, pred_axes.flatten()):
                    pred = model.scan_predict((im, mk))
                    filename = prediction + '/prediction_' + i + '_%03d.png' % (counter)
                    plt.imsave(filename, pred) 
                    counter = counter +1

        </code>
        </pre>
        
        

        
        <h5 class="heading-section">Prediction Results</h5>
        <hr>
        <div class="embed-responsive embed-responsive-16by9">
            <iframe src="https://player.vimeo.com/video/310712744" width="640" height="360" frameborder="0" webkitallowfullscreen mozallowfullscreen allowfullscreen>
            </iframe>
        </div>



        <h5 class="heading-section">Suggested Improvements</h5>
        <hr>
        
        <h6 class="heading">More Data</h6>
        <p>
            Our network was trained on ImageNet data, whereas the original authors trained on multiple datasets for best results. Therefore more data and training would help. In terms of VFX production, adding frames manually painted by artists to the end of the training set could provide added assistance in specializing the net for use on the shot.
        </p>
        
        <h6 class="heading">Modifying the Network</h6>
        <p>
            This CNN only looks at each image in isolation. Combining this network with an LSTM may remove the â€œflickeringâ€ present when the images are shown in sequence. Furthermore, this network only accepts low resolution images. Modifying the network to accept higher resolutions may result in better predictions, though will also require longer training time.
        </p>
        
        
        
        <h5 class="heading-section">Check Out The Full Report</h5>
        <hr>

        <p>
            <a href="https://github.com/joshilp/ImageInpainting/blob/master/Image-Inpainting.pdf">Image-Inpainting.pdf</a>
        </p>
        
        

        <!--Footer-->
        <div id="footer-placeholder"></div>
        <script>
            $(function() {
                $("#footer-placeholder").load("footer.html");
            });

        </script>

    </div>



</body>

</html>
